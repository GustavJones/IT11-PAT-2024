{
  "model": "llama3.2",
  "prompt": "$PROMPT",
  "stream": false
}